#+SETUPFILE: ~/.emacs.d/themes/org-html-themes/setup/theme-readtheorg.setup
#+OPTIONS: \n:t
#+OPTIONS: ^:nil
#+OPTIONS: tex:t
#+STARTUP: latexpreview
#+OPTIONS: tex:dvipng
#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler
#+attr_html: :width 300px
#+attr_latex: :width 300px
#+ATTR_ORG: :width 300

#+TITLE: 程序员的自我修养 - 基于x86 linux2.6


* 第一章 linux内核简介

内核是一个不可分割的静态可执行文件

- 单内核 - 单独的大过程，功能实现基本是函数调用，linux
- 微内核 - 分割为多个独立的过程，少数运行在特权模式，过程间用IPC通信，但实际应用中由于开销比较大，向单内核靠拢

linux版本 主版本号.从版本号.修订版本号.稳定版本号，其中 *从版本号偶数为稳定版*

上下文:
- 运行于用户态，执行用户进程
- 运行于内核空间，处于进程上下文，代表某个特定的进程执行 (int 0x80)
- 运行于内核空间，处于中断上下文，与任何进程无关，处理特定中断， *实际是用了被中断进程的内核栈*

* 第二章 从内核出发

*git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git*
e40152ee1e1c7a63f4777791863215e3faa37a86

iso: http://mirrors.ustc.edu.cn/ubuntu-old-releases/releases/10.04.0/ubuntu-10.04-desktop-i386.iso

#+begin_src txt
###### Ubuntu Main Repos
######

deb http://old-releases.ubuntu.com/ubuntu/ lucid main restricted
deb-src http://old-releases.ubuntu.com/ubuntu/ lucid main restricted
#+end_src

由于linux-2.6内核相对于现在来说很老了，最新的gcc glibc编译老的2.6内核会有各种问题，所以用老的基于linux2.6的系统最为方便

- 软件包推荐
| Name           | Description         |
|----------------+---------------------|
| openssh-server | ssh server          |
| vion           | VNC server，自带    |
| ncurses-dev    | make menuconfig所需 |

- 内核配置
| make config       | 遍历所有配置项 |
| *make menuconfig* | 图形界面工具   |
| make defconfig    | 缺省配置       |
| make oldconfig    | 验证和更新配置 |

- 拷贝本系统配置
#+begin_src bash
  zcat /proc/config.gz > .config  # 如果系统已开启CONFIG_IKCONFIG_PROC
  make oldconfig
#+end_src

- 内核编译
.config配置好以后, 执行make

- 内核安装
1. 生成的arch/i386/boot/bzImage拷到/boot下
2. make modules_install

内核开发的特点
- 无libc库或无标准头文件
- 经常使用编译器扩展特性
内联函数
内联汇编
链接脚本
关于时间戳，是64位的，但是经常也用到高32位，为了防止每次都额外做一次位运算，定义两个符号，指向同一个地址，一个是32位的，一个是64位
likely和unlikely
- 无内存保护
- 浮点
以前的cpu做浮点运算都有个协处理器，这样会使CPU陷入，所以尽量不要用浮点
- 内核栈大小有限，32位机默认是8KB
- *同步和并发* 开了内核抢占和非抢占时锁的行为和中断发生的时为不一样，要特别注意
- 可移植性，尽量做到体系无关

* 第三章 进程管理

- 进程列表存放在任务队列的双向循环链表中 - task list
- task_struct指针在thread_info中，thread_info在内核栈栈底，这样获取thread_info地址简单的方法就是esp & (0xFFFFFFFF << 13)，task_struct就是(esp & (0xFFFFFFFF << 13))->task

*像POWERPC, task_struct指针直接存在r2，相对的说原因之一就是x86的寄存器不够用*

- 默认最大PID是32768
- 进程状态
| TASK_RUNNINNG        | 运行                         |
| TASK_INNTERRUPTIBLE  | 可中断，正在睡眠             |
| TASK_UNINTERRUPTIBLE | 类似可中断，但对信号不做响应 |
| __TASK_TRACED        | 被其他进程跟踪               |
| __TASK_STOPPED       | 进程停止执行                 |
- task->state是进程状态
- 所有进程都是PID为1的init进程的后代， *而init进程的相关数据是静态写在kernel代码里的*, parent是父进程，childern是子进程链表，sibling是兄弟进程链表，同时所有进程在双向链表tasks中
#+begin_src c
struct task_struct {
	volatile long state;	/* -1 unrunnable, 0 runnable, >0 stopped */
	void *stack;
	atomic_t usage;
	unsigned int flags;	/* per process flags, defined below */
	unsigned int ptrace;

	int lock_depth;		/* BKL lock depth */

#ifdef CONFIG_SMP
#ifdef __ARCH_WANT_UNLOCKED_CTXSW
	int oncpu;
#endif
#endif

	int prio, static_prio, normal_prio;
	unsigned int rt_priority;
	const struct sched_class *sched_class;
	struct sched_entity se;
	struct sched_rt_entity rt;

#ifdef CONFIG_PREEMPT_NOTIFIERS
	/* list of struct preempt_notifier: */
	struct hlist_head preempt_notifiers;
#endif

	/*
	 * fpu_counter contains the number of consecutive context switches
	 * that the FPU is used. If this is over a threshold, the lazy fpu
	 * saving becomes unlazy to save the trap. This is an unsigned char
	 * so that after 256 times the counter wraps and the behavior turns
	 * lazy again; this to deal with bursty apps that only use FPU for
	 * a short time
	 */
	unsigned char fpu_counter;
#ifdef CONFIG_BLK_DEV_IO_TRACE
	unsigned int btrace_seq;
#endif

	unsigned int policy;
	cpumask_t cpus_allowed;

#ifdef CONFIG_TREE_PREEMPT_RCU
	int rcu_read_lock_nesting;
	char rcu_read_unlock_special;
	struct rcu_node *rcu_blocked_node;
	struct list_head rcu_node_entry;
#endif /* #ifdef CONFIG_TREE_PREEMPT_RCU */

#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
	struct sched_info sched_info;
#endif

	struct list_head tasks;
	struct plist_node pushable_tasks;

	struct mm_struct *mm, *active_mm;
#if defined(SPLIT_RSS_COUNTING)
	struct task_rss_stat	rss_stat;
#endif
/* task state */
	int exit_state;
	int exit_code, exit_signal;
	int pdeath_signal;  /*  The signal sent when the parent dies  */
	/* ??? */
	unsigned int personality;
	unsigned did_exec:1;
	unsigned in_execve:1;	/* Tell the LSMs that the process is doing an
				 * execve */
	unsigned in_iowait:1;


	/* Revert to default priority/policy when forking */
	unsigned sched_reset_on_fork:1;

	pid_t pid;
	pid_t tgid;

#ifdef CONFIG_CC_STACKPROTECTOR
	/* Canary value for the -fstack-protector gcc feature */
	unsigned long stack_canary;
#endif

	/* 
	 * pointers to (original) parent process, youngest child, younger sibling,
	 * older sibling, respectively.  (p->father can be replaced with 
	 * p->real_parent->pid)
	 */
	struct task_struct *real_parent; /* real parent process */
	struct task_struct *parent; /* recipient of SIGCHLD, wait4() reports */
	/*
	 * children/sibling forms the list of my natural children
	 */
	struct list_head children;	/* list of my children */
	struct list_head sibling;	/* linkage in my parent's children list */
	struct task_struct *group_leader;	/* threadgroup leader */

	/*
	 * ptraced is the list of tasks this task is using ptrace on.
	 * This includes both natural children and PTRACE_ATTACH targets.
	 * p->ptrace_entry is p's link on the p->parent->ptraced list.
	 */
	struct list_head ptraced;
	struct list_head ptrace_entry;

	/*
	 * This is the tracer handle for the ptrace BTS extension.
	 * This field actually belongs to the ptracer task.
	 */
	struct bts_context *bts;

	/* PID/PID hash table linkage. */
	struct pid_link pids[PIDTYPE_MAX];
	struct list_head thread_group;

	struct completion *vfork_done;		/* for vfork() */
	int __user *set_child_tid;		/* CLONE_CHILD_SETTID */
	int __user *clear_child_tid;		/* CLONE_CHILD_CLEARTID */

	cputime_t utime, stime, utimescaled, stimescaled;
	cputime_t gtime;
#ifndef CONFIG_VIRT_CPU_ACCOUNTING
	cputime_t prev_utime, prev_stime;
#endif
	unsigned long nvcsw, nivcsw; /* context switch counts */
	struct timespec start_time; 		/* monotonic time */
	struct timespec real_start_time;	/* boot based time */
/* mm fault and swap info: this can arguably be seen as either mm-specific or thread-specific */
	unsigned long min_flt, maj_flt;

	struct task_cputime cputime_expires;
	struct list_head cpu_timers[3];

/* process credentials */
	const struct cred *real_cred;	/* objective and real subjective task
					 * credentials (COW) */
	const struct cred *cred;	/* effective (overridable) subjective task
					 * credentials (COW) */
	struct mutex cred_guard_mutex;	/* guard against foreign influences on
					 * credential calculations
					 * (notably. ptrace) */
	struct cred *replacement_session_keyring; /* for KEYCTL_SESSION_TO_PARENT */

	char comm[TASK_COMM_LEN]; /* executable name excluding path
				     - access with [gs]et_task_comm (which lock
				       it with task_lock())
				     - initialized normally by setup_new_exec */
/* file system info */
	int link_count, total_link_count;
#ifdef CONFIG_SYSVIPC
/* ipc stuff */
	struct sysv_sem sysvsem;
#endif
#ifdef CONFIG_DETECT_HUNG_TASK
/* hung task detection */
	unsigned long last_switch_count;
#endif
/* CPU-specific state of this task */
	struct thread_struct thread;
/* filesystem information */
	struct fs_struct *fs;
/* open file information */
	struct files_struct *files;
/* namespaces */
	struct nsproxy *nsproxy;
/* signal handlers */
	struct signal_struct *signal;
	struct sighand_struct *sighand;

	sigset_t blocked, real_blocked;
	sigset_t saved_sigmask;	/* restored if set_restore_sigmask() was used */
	struct sigpending pending;

	unsigned long sas_ss_sp;
	size_t sas_ss_size;
	int (*notifier)(void *priv);
	void *notifier_data;
	sigset_t *notifier_mask;
	struct audit_context *audit_context;
#ifdef CONFIG_AUDITSYSCALL
	uid_t loginuid;
	unsigned int sessionid;
#endif
	seccomp_t seccomp;

/* Thread group tracking */
   	u32 parent_exec_id;
   	u32 self_exec_id;
/* Protection of (de-)allocation: mm, files, fs, tty, keyrings, mems_allowed,
 * mempolicy */
	spinlock_t alloc_lock;

#ifdef CONFIG_GENERIC_HARDIRQS
	/* IRQ handler threads */
	struct irqaction *irqaction;
#endif

	/* Protection of the PI data structures: */
	raw_spinlock_t pi_lock;

#ifdef CONFIG_RT_MUTEXES
	/* PI waiters blocked on a rt_mutex held by this task */
	struct plist_head pi_waiters;
	/* Deadlock detection and priority inheritance handling */
	struct rt_mutex_waiter *pi_blocked_on;
#endif

#ifdef CONFIG_DEBUG_MUTEXES
	/* mutex deadlock detection */
	struct mutex_waiter *blocked_on;
#endif
#ifdef CONFIG_TRACE_IRQFLAGS
	unsigned int irq_events;
	unsigned long hardirq_enable_ip;
	unsigned long hardirq_disable_ip;
	unsigned int hardirq_enable_event;
	unsigned int hardirq_disable_event;
	int hardirqs_enabled;
	int hardirq_context;
	unsigned long softirq_disable_ip;
	unsigned long softirq_enable_ip;
	unsigned int softirq_disable_event;
	unsigned int softirq_enable_event;
	int softirqs_enabled;
	int softirq_context;
#endif
#ifdef CONFIG_LOCKDEP
# define MAX_LOCK_DEPTH 48UL
	u64 curr_chain_key;
	int lockdep_depth;
	unsigned int lockdep_recursion;
	struct held_lock held_locks[MAX_LOCK_DEPTH];
	gfp_t lockdep_reclaim_gfp;
#endif

/* journalling filesystem info */
	void *journal_info;

/* stacked block device info */
	struct bio_list *bio_list;

/* VM state */
	struct reclaim_state *reclaim_state;

	struct backing_dev_info *backing_dev_info;

	struct io_context *io_context;

	unsigned long ptrace_message;
	siginfo_t *last_siginfo; /* For ptrace use.  */
	struct task_io_accounting ioac;
#if defined(CONFIG_TASK_XACCT)
	u64 acct_rss_mem1;	/* accumulated rss usage */
	u64 acct_vm_mem1;	/* accumulated virtual memory usage */
	cputime_t acct_timexpd;	/* stime + utime since last update */
#endif
#ifdef CONFIG_CPUSETS
	nodemask_t mems_allowed;	/* Protected by alloc_lock */
	int cpuset_mem_spread_rotor;
#endif
#ifdef CONFIG_CGROUPS
	/* Control Group info protected by css_set_lock */
	struct css_set *cgroups;
	/* cg_list protected by css_set_lock and tsk->alloc_lock */
	struct list_head cg_list;
#endif
#ifdef CONFIG_FUTEX
	struct robust_list_head __user *robust_list;
#ifdef CONFIG_COMPAT
	struct compat_robust_list_head __user *compat_robust_list;
#endif
	struct list_head pi_state_list;
	struct futex_pi_state *pi_state_cache;
#endif
#ifdef CONFIG_PERF_EVENTS
	struct perf_event_context *perf_event_ctxp;
	struct mutex perf_event_mutex;
	struct list_head perf_event_list;
#endif
#ifdef CONFIG_NUMA
	struct mempolicy *mempolicy;	/* Protected by alloc_lock */
	short il_next;
#endif
	atomic_t fs_excl;	/* holding fs exclusive resources */
	struct rcu_head rcu;

	/*
	 * cache last used pipe for splice
	 */
	struct pipe_inode_info *splice_pipe;
#ifdef	CONFIG_TASK_DELAY_ACCT
	struct task_delay_info *delays;
#endif
#ifdef CONFIG_FAULT_INJECTION
	int make_it_fail;
#endif
	struct prop_local_single dirties;
#ifdef CONFIG_LATENCYTOP
	int latency_record_count;
	struct latency_record latency_record[LT_SAVECOUNT];
#endif
	/*
	 * time slack values; these are used to round up poll() and
	 * select() etc timeout values. These are in nanoseconds.
	 */
	unsigned long timer_slack_ns;
	unsigned long default_timer_slack_ns;

	struct list_head	*scm_work_list;
#ifdef CONFIG_FUNCTION_GRAPH_TRACER
	/* Index of current stored address in ret_stack */
	int curr_ret_stack;
	/* Stack of return addresses for return function tracing */
	struct ftrace_ret_stack	*ret_stack;
	/* time stamp for last schedule */
	unsigned long long ftrace_timestamp;
	/*
	 * Number of functions that haven't been traced
	 * because of depth overrun.
	 */
	atomic_t trace_overrun;
	/* Pause for the tracing */
	atomic_t tracing_graph_pause;
#endif
#ifdef CONFIG_TRACING
	/* state flags for use by tracers */
	unsigned long trace;
	/* bitmask of trace recursion */
	unsigned long trace_recursion;
#endif /* CONFIG_TRACING */
#ifdef CONFIG_CGROUP_MEM_RES_CTLR /* memcg uses this to do batch job */
	struct memcg_batch_info {
		int do_batch;	/* incremented when batch uncharge started */
		struct mem_cgroup *memcg; /* target memcg of uncharge */
		unsigned long bytes; 		/* uncharged usage */
		unsigned long memsw_bytes; /* uncharged mem+swap usage */
	} memcg_batch;
#endif
};

struct thread_info {
	struct task_struct	*task;		/* main task structure */
	struct exec_domain	*exec_domain;	/* execution domain */
	__u32			flags;		/* low level flags */
	__u32			status;		/* thread synchronous flags */
	__u32			cpu;		/* current CPU */
	int			preempt_count;	/* 0 => preemptable,
						   <0 => BUG */
	mm_segment_t		addr_limit;
	struct restart_block    restart_block;
	void __user		*sysenter_return;
#ifdef CONFIG_X86_32
	unsigned long           previous_esp;   /* ESP of the previous stack in
						   case of nested (IRQ) stacks
						*/
	__u8			supervisor_stack[0];
#endif
	int			uaccess_err;
};
#+end_src
- 写时拷贝,页权限设为只读，真正要写的时候再拷贝新页

- 用户态fork -> 用户态clone -> 内核态do_fork -> copy_process:
dup_task_struct
检查进程资源限制
子进程task_struct某些信息清0
子进程state = UNINTERRUPTIBLE
copy_flags
alloc_pid申请子进程pid
资源分配
- vfork为了那些马上exec的进程使用，不推荐
- linux进程与线程的区别只在与是否共享某些资源

| CLONE 参数标志       | 含义                                 |
|----------------------+--------------------------------------|
| CLONE_FILES          | 共享打开的文件                       |
| CLONE_FS             | 共享文件系统信息                     |
| CLONE_IDLETASK       | PID设为0(dedicated for init process) |
| CLONE_NEWNS          | 子进程有新的命令空间                 |
| CLONE_PARENT         | 子进程与父进程拥有同一个父进程       |
| CLONE_PTRACE         | 调试子进程，gdb会用这个              |
| CLONE_SETTID         | 将TID回写至用户空间                  |
| CLONE_SETTLS         | 为子进程创建新的TLS                  |
| CLONE_SIGHAND        | 共享信号处理函数及被阻断的信号       |
| CLONE_SYSVEM         | 共享SytemV SEM_UNDO语义              |
| CLONE_THREAD         | 相同的线程组                         |
| CLONE_VFORK          | vfork()使用                          |
| CLONE_UNTRACED       | 防止被trace,主要是防止跟踪           |
| CLONE_STOP           | 以TASK_STOPPED状态开始进程           |
| CLONE_CHILD_CLEARTID | 清除子进程的TID                      |
| CLONE_CHILD_SETTID   | 设置子进程的TID                      |
| CLONE_PARENT_SETTID  | 设置父进程的TID                      |
| CLONE_VM             | *共享地址空间*                       |

- 内核线程，没用用户空间的线程， mm为NULL, 相关头文件为kthread.h
- exit -> do_exit，永不返回
task_struct标志PF_EXITING
del_timer_sync
exit_sem, exit_mm, exit_files, exit_fs
设置exit_code
exit_notify让其父进程为其子进程重新设置父进程，同时设状态为ZOMBIE
schedule，父进程通过wait帮其清理内核栈, thread_info，task_struct
- wait
为退出进程的子进程找新的父进程
为被退出进程trace的进程找新的父进程

* 第四章 进程调度

- preemption 内核调度程序决定进程挂起与运行
- yielding   进程本身主动挂起
- 进程调度在响应时间和吞吐量之间做平衡
- 传统的绝对时间片会引发的固定的切换频率问题，linux使用了公平调度
se 是调度器实体
vruntime 虚拟实时，系统定时器周期性调用update_curr()更新

#+begin_src c
struct sched_entity {
	struct load_weight	load;		/* for load-balancing */
	struct rb_node		run_node;
	struct list_head	group_node;
	unsigned int		on_rq;

	u64			exec_start;
	u64			sum_exec_runtime;
	u64			vruntime;
	u64			prev_sum_exec_runtime;

	u64			last_wakeup;
	u64			avg_overlap;

	u64			nr_migrations;

	u64			start_runtime;
	u64			avg_wakeup;
//...
};

static void update_curr(struct cfs_rq *cfs_rq)
{
	struct sched_entity *curr = cfs_rq->curr;
	u64 now = rq_of(cfs_rq)->clock;
	unsigned long delta_exec;

	if (unlikely(!curr))
		return;

	/*
	 * Get the amount of time the current task was running
	 * since the last time we changed load (this cannot
	 * overflow on 32 bits):
	 */
	delta_exec = (unsigned long)(now - curr->exec_start);
	if (!delta_exec)
		return;

	__update_curr(cfs_rq, curr, delta_exec);
	curr->exec_start = now;

	if (entity_is_task(curr)) {
		struct task_struct *curtask = task_of(curr);

		trace_sched_stat_runtime(curtask, delta_exec, curr->vruntime);
		cpuacct_charge(curtask, delta_exec);
		account_group_exec_runtime(curtask, delta_exec);
	}
}

static inline void
__update_curr(struct cfs_rq *cfs_rq, struct sched_entity *curr,
	      unsigned long delta_exec)
{
	unsigned long delta_exec_weighted;

	schedstat_set(curr->exec_max, max((u64)delta_exec, curr->exec_max));

	curr->sum_exec_runtime += delta_exec;
	schedstat_add(cfs_rq, exec_clock, delta_exec);
	delta_exec_weighted = calc_delta_fair(delta_exec, curr);

	curr->vruntime += delta_exec_weighted;
	update_min_vruntime(cfs_rq);
}

#+end_src

- 进程选择
红黑树
enqueue_entity +进程
dequeue_entity -进程
#+begin_src c
static struct sched_entity *__pick_next_entity(struct cfs_rq *cfs_rq)
{
	struct rb_node *left = cfs_rq->rb_leftmost;

	if (!left)
		return NULL;

	return rb_entry(left, struct sched_entity, run_node);
}


#+end_src

- 调度器函数 schedule->pick_next_task，会从高优先级到低优先级调度器类中找第一个进程
- 休眠
从可执行红黑树中移出，放入等待队列
#+begin_src c
DEFINE_WAIT(wait); //创建队列项
add_wait_queue(q, &wait); //加入等待队列
while(!condition) {
//条件不满足
    prepare_to_wait(&q, &wait, TASK_INTERRUPTIBLE); //设置进程状态，如果此时已退出等待队列，重新加入
    if(signal_pending(current)) //处理信号
    schedule();//调度
}
finish_wait(&q, &wait);//结束等待
#+end_src
- 唤醒
从等待队列移到红黑树
- 抢占和上下文切换
switch_mm 切换虚拟内存映射
switch_to 切换寄存器组
