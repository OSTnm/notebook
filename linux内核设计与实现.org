#+SETUPFILE: ~/.emacs.d/themes/org-html-themes/setup/theme-readtheorg.setup
#+OPTIONS: \n:t
#+OPTIONS: ^:nil
#+OPTIONS: tex:t
#+STARTUP: latexpreview
#+OPTIONS: tex:dvipng
#+HTML_MATHJAX: align: left indent: 5em tagside: left font: Neo-Euler
#+attr_html: :width 300px
#+attr_latex: :width 300px
#+ATTR_ORG: :width 300

#+TITLE: 程序员的自我修养 - 基于x86 linux2.6


* 第一章 linux内核简介

内核是一个不可分割的静态可执行文件

- 单内核 - 单独的大过程，功能实现基本是函数调用，linux
- 微内核 - 分割为多个独立的过程，少数运行在特权模式，过程间用IPC通信，但实际应用中由于开销比较大，向单内核靠拢

linux版本 主版本号.从版本号.修订版本号.稳定版本号，其中 *从版本号偶数为稳定版*

上下文:
- 运行于用户态，执行用户进程
- 运行于内核空间，处于进程上下文，代表某个特定的进程执行 (int 0x80)
- 运行于内核空间，处于中断上下文，与任何进程无关，处理特定中断， *实际是用了被中断进程的内核栈*

* 第二章 从内核出发

*git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git*
e40152ee1e1c7a63f4777791863215e3faa37a86

iso: http://mirrors.ustc.edu.cn/ubuntu-old-releases/releases/10.04.0/ubuntu-10.04-desktop-i386.iso

#+begin_src txt
###### Ubuntu Main Repos
######

deb http://old-releases.ubuntu.com/ubuntu/ lucid main restricted
deb-src http://old-releases.ubuntu.com/ubuntu/ lucid main restricted
#+end_src

由于linux-2.6内核相对于现在来说很老了，最新的gcc glibc编译老的2.6内核会有各种问题，所以用老的基于linux2.6的系统最为方便

- 软件包推荐
| Name           | Description         |
|----------------+---------------------|
| openssh-server | ssh server          |
| vion           | VNC server，自带    |
| ncurses-dev    | make menuconfig所需 |

- 内核配置
| make config       | 遍历所有配置项 |
| *make menuconfig* | 图形界面工具   |
| make defconfig    | 缺省配置       |
| make oldconfig    | 验证和更新配置 |

- 拷贝本系统配置
#+begin_src bash
  zcat /proc/config.gz > .config  # 如果系统已开启CONFIG_IKCONFIG_PROC
  make oldconfig
#+end_src

- 内核编译
.config配置好以后, 执行make

- 内核安装
1. 生成的arch/i386/boot/bzImage拷到/boot下
2. make modules_install

内核开发的特点
- 无libc库或无标准头文件
- 经常使用编译器扩展特性
内联函数
内联汇编
链接脚本
关于时间戳，是64位的，但是经常也用到高32位，为了防止每次都额外做一次位运算，定义两个符号，指向同一个地址，一个是32位的，一个是64位
likely和unlikely
- 无内存保护
- 浮点
以前的cpu做浮点运算都有个协处理器，这样会使CPU陷入，所以尽量不要用浮点
- 内核栈大小有限，32位机默认是8KB
- *同步和并发* 开了内核抢占和非抢占时锁的行为和中断发生的时为不一样，要特别注意
- 可移植性，尽量做到体系无关

* 第三章 进程管理

- 进程列表存放在任务队列的双向循环链表中 - task list
- task_struct指针在thread_info中，thread_info在内核栈栈底，这样获取thread_info地址简单的方法就是esp & (0xFFFFFFFF << 13)，task_struct就是(esp & (0xFFFFFFFF << 13))->task

*像POWERPC, task_struct指针直接存在r2，相对的说原因之一就是x86的寄存器不够用*

- 默认最大PID是32768
- 进程状态
| TASK_RUNNINNG        | 运行                         |
| TASK_INNTERRUPTIBLE  | 可中断，正在睡眠             |
| TASK_UNINTERRUPTIBLE | 类似可中断，但对信号不做响应 |
| __TASK_TRACED        | 被其他进程跟踪               |
| __TASK_STOPPED       | 进程停止执行                 |
- task->state是进程状态
- 所有进程都是PID为1的init进程的后代， *而init进程的相关数据是静态写在kernel代码里的*, parent是父进程，childern是子进程链表，sibling是兄弟进程链表，同时所有进程在双向链表tasks中
#+begin_src c
struct task_struct {
	volatile long state;	/* -1 unrunnable, 0 runnable, >0 stopped */
	void *stack;
	atomic_t usage;
	unsigned int flags;	/* per process flags, defined below */
	unsigned int ptrace;

	int lock_depth;		/* BKL lock depth */

#ifdef CONFIG_SMP
#ifdef __ARCH_WANT_UNLOCKED_CTXSW
	int oncpu;
#endif
#endif

	int prio, static_prio, normal_prio;
	unsigned int rt_priority;
	const struct sched_class *sched_class;
	struct sched_entity se;
	struct sched_rt_entity rt;

#ifdef CONFIG_PREEMPT_NOTIFIERS
	/* list of struct preempt_notifier: */
	struct hlist_head preempt_notifiers;
#endif

	/*
	 * fpu_counter contains the number of consecutive context switches
	 * that the FPU is used. If this is over a threshold, the lazy fpu
	 * saving becomes unlazy to save the trap. This is an unsigned char
	 * so that after 256 times the counter wraps and the behavior turns
	 * lazy again; this to deal with bursty apps that only use FPU for
	 * a short time
	 */
	unsigned char fpu_counter;
#ifdef CONFIG_BLK_DEV_IO_TRACE
	unsigned int btrace_seq;
#endif

	unsigned int policy;
	cpumask_t cpus_allowed;

#ifdef CONFIG_TREE_PREEMPT_RCU
	int rcu_read_lock_nesting;
	char rcu_read_unlock_special;
	struct rcu_node *rcu_blocked_node;
	struct list_head rcu_node_entry;
#endif /* #ifdef CONFIG_TREE_PREEMPT_RCU */

#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
	struct sched_info sched_info;
#endif

	struct list_head tasks;
	struct plist_node pushable_tasks;

	struct mm_struct *mm, *active_mm;
#if defined(SPLIT_RSS_COUNTING)
	struct task_rss_stat	rss_stat;
#endif
/* task state */
	int exit_state;
	int exit_code, exit_signal;
	int pdeath_signal;  /*  The signal sent when the parent dies  */
	/* ??? */
	unsigned int personality;
	unsigned did_exec:1;
	unsigned in_execve:1;	/* Tell the LSMs that the process is doing an
				 * execve */
	unsigned in_iowait:1;


	/* Revert to default priority/policy when forking */
	unsigned sched_reset_on_fork:1;

	pid_t pid;
	pid_t tgid;

#ifdef CONFIG_CC_STACKPROTECTOR
	/* Canary value for the -fstack-protector gcc feature */
	unsigned long stack_canary;
#endif

	/* 
	 * pointers to (original) parent process, youngest child, younger sibling,
	 * older sibling, respectively.  (p->father can be replaced with 
	 * p->real_parent->pid)
	 */
	struct task_struct *real_parent; /* real parent process */
	struct task_struct *parent; /* recipient of SIGCHLD, wait4() reports */
	/*
	 * children/sibling forms the list of my natural children
	 */
	struct list_head children;	/* list of my children */
	struct list_head sibling;	/* linkage in my parent's children list */
	struct task_struct *group_leader;	/* threadgroup leader */

	/*
	 * ptraced is the list of tasks this task is using ptrace on.
	 * This includes both natural children and PTRACE_ATTACH targets.
	 * p->ptrace_entry is p's link on the p->parent->ptraced list.
	 */
	struct list_head ptraced;
	struct list_head ptrace_entry;

	/*
	 * This is the tracer handle for the ptrace BTS extension.
	 * This field actually belongs to the ptracer task.
	 */
	struct bts_context *bts;

	/* PID/PID hash table linkage. */
	struct pid_link pids[PIDTYPE_MAX];
	struct list_head thread_group;

	struct completion *vfork_done;		/* for vfork() */
	int __user *set_child_tid;		/* CLONE_CHILD_SETTID */
	int __user *clear_child_tid;		/* CLONE_CHILD_CLEARTID */

	cputime_t utime, stime, utimescaled, stimescaled;
	cputime_t gtime;
#ifndef CONFIG_VIRT_CPU_ACCOUNTING
	cputime_t prev_utime, prev_stime;
#endif
	unsigned long nvcsw, nivcsw; /* context switch counts */
	struct timespec start_time; 		/* monotonic time */
	struct timespec real_start_time;	/* boot based time */
/* mm fault and swap info: this can arguably be seen as either mm-specific or thread-specific */
	unsigned long min_flt, maj_flt;

	struct task_cputime cputime_expires;
	struct list_head cpu_timers[3];

/* process credentials */
	const struct cred *real_cred;	/* objective and real subjective task
					 * credentials (COW) */
	const struct cred *cred;	/* effective (overridable) subjective task
					 * credentials (COW) */
	struct mutex cred_guard_mutex;	/* guard against foreign influences on
					 * credential calculations
					 * (notably. ptrace) */
	struct cred *replacement_session_keyring; /* for KEYCTL_SESSION_TO_PARENT */

	char comm[TASK_COMM_LEN]; /* executable name excluding path
				     - access with [gs]et_task_comm (which lock
				       it with task_lock())
				     - initialized normally by setup_new_exec */
/* file system info */
	int link_count, total_link_count;
#ifdef CONFIG_SYSVIPC
/* ipc stuff */
	struct sysv_sem sysvsem;
#endif
#ifdef CONFIG_DETECT_HUNG_TASK
/* hung task detection */
	unsigned long last_switch_count;
#endif
/* CPU-specific state of this task */
	struct thread_struct thread;
/* filesystem information */
	struct fs_struct *fs;
/* open file information */
	struct files_struct *files;
/* namespaces */
	struct nsproxy *nsproxy;
/* signal handlers */
	struct signal_struct *signal;
	struct sighand_struct *sighand;

	sigset_t blocked, real_blocked;
	sigset_t saved_sigmask;	/* restored if set_restore_sigmask() was used */
	struct sigpending pending;

	unsigned long sas_ss_sp;
	size_t sas_ss_size;
	int (*notifier)(void *priv);
	void *notifier_data;
	sigset_t *notifier_mask;
	struct audit_context *audit_context;
#ifdef CONFIG_AUDITSYSCALL
	uid_t loginuid;
	unsigned int sessionid;
#endif
	seccomp_t seccomp;

/* Thread group tracking */
   	u32 parent_exec_id;
   	u32 self_exec_id;
/* Protection of (de-)allocation: mm, files, fs, tty, keyrings, mems_allowed,
 * mempolicy */
	spinlock_t alloc_lock;

#ifdef CONFIG_GENERIC_HARDIRQS
	/* IRQ handler threads */
	struct irqaction *irqaction;
#endif

	/* Protection of the PI data structures: */
	raw_spinlock_t pi_lock;

#ifdef CONFIG_RT_MUTEXES
	/* PI waiters blocked on a rt_mutex held by this task */
	struct plist_head pi_waiters;
	/* Deadlock detection and priority inheritance handling */
	struct rt_mutex_waiter *pi_blocked_on;
#endif

#ifdef CONFIG_DEBUG_MUTEXES
	/* mutex deadlock detection */
	struct mutex_waiter *blocked_on;
#endif
#ifdef CONFIG_TRACE_IRQFLAGS
	unsigned int irq_events;
	unsigned long hardirq_enable_ip;
	unsigned long hardirq_disable_ip;
	unsigned int hardirq_enable_event;
	unsigned int hardirq_disable_event;
	int hardirqs_enabled;
	int hardirq_context;
	unsigned long softirq_disable_ip;
	unsigned long softirq_enable_ip;
	unsigned int softirq_disable_event;
	unsigned int softirq_enable_event;
	int softirqs_enabled;
	int softirq_context;
#endif
#ifdef CONFIG_LOCKDEP
# define MAX_LOCK_DEPTH 48UL
	u64 curr_chain_key;
	int lockdep_depth;
	unsigned int lockdep_recursion;
	struct held_lock held_locks[MAX_LOCK_DEPTH];
	gfp_t lockdep_reclaim_gfp;
#endif

/* journalling filesystem info */
	void *journal_info;

/* stacked block device info */
	struct bio_list *bio_list;

/* VM state */
	struct reclaim_state *reclaim_state;

	struct backing_dev_info *backing_dev_info;

	struct io_context *io_context;

	unsigned long ptrace_message;
	siginfo_t *last_siginfo; /* For ptrace use.  */
	struct task_io_accounting ioac;
#if defined(CONFIG_TASK_XACCT)
	u64 acct_rss_mem1;	/* accumulated rss usage */
	u64 acct_vm_mem1;	/* accumulated virtual memory usage */
	cputime_t acct_timexpd;	/* stime + utime since last update */
#endif
#ifdef CONFIG_CPUSETS
	nodemask_t mems_allowed;	/* Protected by alloc_lock */
	int cpuset_mem_spread_rotor;
#endif
#ifdef CONFIG_CGROUPS
	/* Control Group info protected by css_set_lock */
	struct css_set *cgroups;
	/* cg_list protected by css_set_lock and tsk->alloc_lock */
	struct list_head cg_list;
#endif
#ifdef CONFIG_FUTEX
	struct robust_list_head __user *robust_list;
#ifdef CONFIG_COMPAT
	struct compat_robust_list_head __user *compat_robust_list;
#endif
	struct list_head pi_state_list;
	struct futex_pi_state *pi_state_cache;
#endif
#ifdef CONFIG_PERF_EVENTS
	struct perf_event_context *perf_event_ctxp;
	struct mutex perf_event_mutex;
	struct list_head perf_event_list;
#endif
#ifdef CONFIG_NUMA
	struct mempolicy *mempolicy;	/* Protected by alloc_lock */
	short il_next;
#endif
	atomic_t fs_excl;	/* holding fs exclusive resources */
	struct rcu_head rcu;

	/*
	 * cache last used pipe for splice
	 */
	struct pipe_inode_info *splice_pipe;
#ifdef	CONFIG_TASK_DELAY_ACCT
	struct task_delay_info *delays;
#endif
#ifdef CONFIG_FAULT_INJECTION
	int make_it_fail;
#endif
	struct prop_local_single dirties;
#ifdef CONFIG_LATENCYTOP
	int latency_record_count;
	struct latency_record latency_record[LT_SAVECOUNT];
#endif
	/*
	 * time slack values; these are used to round up poll() and
	 * select() etc timeout values. These are in nanoseconds.
	 */
	unsigned long timer_slack_ns;
	unsigned long default_timer_slack_ns;

	struct list_head	*scm_work_list;
#ifdef CONFIG_FUNCTION_GRAPH_TRACER
	/* Index of current stored address in ret_stack */
	int curr_ret_stack;
	/* Stack of return addresses for return function tracing */
	struct ftrace_ret_stack	*ret_stack;
	/* time stamp for last schedule */
	unsigned long long ftrace_timestamp;
	/*
	 * Number of functions that haven't been traced
	 * because of depth overrun.
	 */
	atomic_t trace_overrun;
	/* Pause for the tracing */
	atomic_t tracing_graph_pause;
#endif
#ifdef CONFIG_TRACING
	/* state flags for use by tracers */
	unsigned long trace;
	/* bitmask of trace recursion */
	unsigned long trace_recursion;
#endif /* CONFIG_TRACING */
#ifdef CONFIG_CGROUP_MEM_RES_CTLR /* memcg uses this to do batch job */
	struct memcg_batch_info {
		int do_batch;	/* incremented when batch uncharge started */
		struct mem_cgroup *memcg; /* target memcg of uncharge */
		unsigned long bytes; 		/* uncharged usage */
		unsigned long memsw_bytes; /* uncharged mem+swap usage */
	} memcg_batch;
#endif
};

struct thread_info {
	struct task_struct	*task;		/* main task structure */
	struct exec_domain	*exec_domain;	/* execution domain */
	__u32			flags;		/* low level flags */
	__u32			status;		/* thread synchronous flags */
	__u32			cpu;		/* current CPU */
	int			preempt_count;	/* 0 => preemptable,
						   <0 => BUG */
	mm_segment_t		addr_limit;
	struct restart_block    restart_block;
	void __user		*sysenter_return;
#ifdef CONFIG_X86_32
	unsigned long           previous_esp;   /* ESP of the previous stack in
						   case of nested (IRQ) stacks
						*/
	__u8			supervisor_stack[0];
#endif
	int			uaccess_err;
};
#+end_src
- 写时拷贝,页权限设为只读，真正要写的时候再拷贝新页

- 用户态fork -> 用户态clone -> 内核态do_fork -> copy_process:
dup_task_struct
检查进程资源限制
子进程task_struct某些信息清0
子进程state = UNINTERRUPTIBLE
copy_flags
alloc_pid申请子进程pid
资源分配
- vfork为了那些马上exec的进程使用，不推荐
- linux进程与线程的区别只在与是否共享某些资源

| CLONE 参数标志       | 含义                                 |
|----------------------+--------------------------------------|
| CLONE_FILES          | 共享打开的文件                       |
| CLONE_FS             | 共享文件系统信息                     |
| CLONE_IDLETASK       | PID设为0(dedicated for init process) |
| CLONE_NEWNS          | 子进程有新的命令空间                 |
| CLONE_PARENT         | 子进程与父进程拥有同一个父进程       |
| CLONE_PTRACE         | 调试子进程，gdb会用这个              |
| CLONE_SETTID         | 将TID回写至用户空间                  |
| CLONE_SETTLS         | 为子进程创建新的TLS                  |
| CLONE_SIGHAND        | 共享信号处理函数及被阻断的信号       |
| CLONE_SYSVEM         | 共享SytemV SEM_UNDO语义              |
| CLONE_THREAD         | 相同的线程组                         |
| CLONE_VFORK          | vfork()使用                          |
| CLONE_UNTRACED       | 防止被trace,主要是防止跟踪           |
| CLONE_STOP           | 以TASK_STOPPED状态开始进程           |
| CLONE_CHILD_CLEARTID | 清除子进程的TID                      |
| CLONE_CHILD_SETTID   | 设置子进程的TID                      |
| CLONE_PARENT_SETTID  | 设置父进程的TID                      |
| CLONE_VM             | *共享地址空间*                       |

- 内核线程，没用用户空间的线程， mm为NULL, 相关头文件为kthread.h
- exit -> do_exit，永不返回
task_struct标志PF_EXITING
del_timer_sync
exit_sem, exit_mm, exit_files, exit_fs
设置exit_code
exit_notify让其父进程为其子进程重新设置父进程，同时设状态为ZOMBIE
schedule，父进程通过wait帮其清理内核栈, thread_info，task_struct
- wait
为退出进程的子进程找新的父进程
为被退出进程trace的进程找新的父进程

* 第四章 进程调度

- preemption 内核调度程序决定进程挂起与运行
- yielding   进程本身主动挂起
- 进程调度在响应时间和吞吐量之间做平衡
- 传统的绝对时间片会引发的固定的切换频率问题，linux使用了公平调度
se 是调度器实体
vruntime 虚拟实时，系统定时器周期性调用update_curr()更新

#+begin_src c
struct sched_entity {
	struct load_weight	load;		/* for load-balancing */
	struct rb_node		run_node;
	struct list_head	group_node;
	unsigned int		on_rq;

	u64			exec_start;
	u64			sum_exec_runtime;
	u64			vruntime;
	u64			prev_sum_exec_runtime;

	u64			last_wakeup;
	u64			avg_overlap;

	u64			nr_migrations;

	u64			start_runtime;
	u64			avg_wakeup;
//...
};

static void update_curr(struct cfs_rq *cfs_rq)
{
	struct sched_entity *curr = cfs_rq->curr;
	u64 now = rq_of(cfs_rq)->clock;
	unsigned long delta_exec;

	if (unlikely(!curr))
		return;

	/*
	 * Get the amount of time the current task was running
	 * since the last time we changed load (this cannot
	 * overflow on 32 bits):
	 */
	delta_exec = (unsigned long)(now - curr->exec_start);
	if (!delta_exec)
		return;

	__update_curr(cfs_rq, curr, delta_exec);
	curr->exec_start = now;

	if (entity_is_task(curr)) {
		struct task_struct *curtask = task_of(curr);

		trace_sched_stat_runtime(curtask, delta_exec, curr->vruntime);
		cpuacct_charge(curtask, delta_exec);
		account_group_exec_runtime(curtask, delta_exec);
	}
}

static inline void
__update_curr(struct cfs_rq *cfs_rq, struct sched_entity *curr,
	      unsigned long delta_exec)
{
	unsigned long delta_exec_weighted;

	schedstat_set(curr->exec_max, max((u64)delta_exec, curr->exec_max));

	curr->sum_exec_runtime += delta_exec;
	schedstat_add(cfs_rq, exec_clock, delta_exec);
	delta_exec_weighted = calc_delta_fair(delta_exec, curr);

	curr->vruntime += delta_exec_weighted;
	update_min_vruntime(cfs_rq);
}

#+end_src

- 进程选择
红黑树
enqueue_entity +进程
dequeue_entity -进程
#+begin_src c
static struct sched_entity *__pick_next_entity(struct cfs_rq *cfs_rq)
{
	struct rb_node *left = cfs_rq->rb_leftmost;

	if (!left)
		return NULL;

	return rb_entry(left, struct sched_entity, run_node);
}


#+end_src

- 调度器函数 schedule->pick_next_task，会从高优先级到低优先级调度器类中找第一个进程
- 休眠
从可执行红黑树中移出，放入等待队列
#+begin_src c
DEFINE_WAIT(wait); //创建队列项
add_wait_queue(q, &wait); //加入等待队列
while(!condition) {
//条件不满足
    prepare_to_wait(&q, &wait, TASK_INTERRUPTIBLE); //设置进程状态，如果此时已退出等待队列，重新加入
    if(signal_pending(current)) //处理信号
    schedule();//调度
}
finish_wait(&q, &wait);//结束等待
#+end_src
- 唤醒
从等待队列移到红黑树
- 上下文切换
switch_mm 切换虚拟内存映射
switch_to 切换寄存器组
- 用户抢占
发生在系统调用或中断处理程序返回用户空间
- 内核抢占
*非内核抢占的操作系统中，调度程序没有办法在一个内核级的任务正在执行的时候重新调度*
thread_info->preempt_count为0时，可抢占(此时是否重新调度取决于need_resched)
a. 中断处理程序返回内核空间
b. 内核代码再一次有抢占性
c. 显示调用schedule
d. 内核任务阻塞(一般是加到等待队列，同时调用schedule)
- 实时调度策略
在sched_rt.c中,之前的CFS在sched_fair.c(SCHED_NORMAL)中
a. SCHED_FIFO, 一直执行到主动放弃或被更高优先级抢占
b. SCHED_RR, 带时间片的SCHED_FIFO
实时优先级为静态优先级，不像普通进程会动态计算优先级
- 优先级范围
nice -20~+19 相当于 实时优先级 100~139
#+begin_src c
/*
 * Priority of a process goes from 0..MAX_PRIO-1, valid RT
 * priority is 0..MAX_RT_PRIO-1, and SCHED_NORMAL/SCHED_BATCH
 * tasks are in the range MAX_RT_PRIO..MAX_PRIO-1. Priority
 * values are inverted: lower p->prio value means higher priority.
 *
 * The MAX_USER_RT_PRIO value allows the actual maximum
 * RT priority to be separate from the value exported to
 * user-space.  This allows kernel threads to set their
 * priority to a value higher than any user task. Note:
 * MAX_RT_PRIO must not be smaller than MAX_USER_RT_PRIO.
 */

#define MAX_USER_RT_PRIO	100
#define MAX_RT_PRIO		MAX_USER_RT_PRIO

#define MAX_PRIO		(MAX_RT_PRIO + 40)
#define DEFAULT_PRIO		(MAX_RT_PRIO + 20)
#+end_src

* 第五章 系统调用

除异常和陷入外内核唯一的合法入口
*当进程从用户态切换至内核栈时,X86会进行栈切换(取出tss段中的esp0)*
*需保证系统调用是可重入的,因为进程上下文中，内核可被抢占，所以同时可能存在多个相同的系统调用*
*反过来说中断处理程序不能休眠*

*asmlinkage* 限制词表示用栈传数据
sys_call_table 是内核的系统调用表

#+begin_src c
//entry_32.S
syscall_call:
	call *sys_call_table(,%eax,4)
	movl %eax,PT_EAX(%esp)		# store the return value

//entry_64.S
ENTRY(system_call)
	CFI_STARTPROC	simple
	CFI_SIGNAL_FRAME
	CFI_DEF_CFA	rsp,KERNEL_STACK_OFFSET
	CFI_REGISTER	rip,rcx
	/*CFI_REGISTER	rflags,r11*/
	SWAPGS_UNSAFE_STACK
#+end_src

内核和用户空间间做数据传输时有可能会引起阻塞（所需页在磁盘上）
- copy_from_user 从用户空间拷贝
- copy_to_user   拷贝到用户空间

capable可检查是否可操作指定资源

** 新增系统调用
*** 环境
- linux kernel
a. make defconfig
b. make menuconfig
#+begin_src bash
# make menuconfig
[ ] Network packet filtering framework (Netfilter)  --->
#+end_src
c. make
- busybox
*git://git.busybox.net/busybox*
e50f74da70da645c25d7daa81b2d9796a738f718 tag: 1_24_2

a. make menuconfig
#+begin_src bash
# make menuconfig
[*] Don't use /usr
[*] Build BusyBox as a static binary (no shared libs)
[ ] sync
#+end_src
b. make
c. make install
- initramfs
a. 建立目录
#+begin_src bash
#!/bin/bash
mkdir -pv initramfs/x86-busybox
cd initramfs/x86-busybox
mkdir -pv {bin,sbin,etc,proc,sys,usr/{bin,sbin}}
cp -av /mnt/hgfs/linux-2.6-git/busybox/_install/* .
#+end_src
b. 在目录下建立init
#+begin_src sh
#!/bin/sh
mount -t proc none /proc
mount -t sysfs none /sys
echo -e "\nBoot took $(cut -d' ' -f1 /proc/uptime) seconds\n"
exec /bin/sh
#+end_src
c. 生成initramfs
在目录下
find . -print0 | cpio --null -ov --format=newc | gzip -9 > x86.cpio.gz
- qemu
qemu -kernel bzImage -initrd ./x86.cpio.gz -nographic -append "console=ttyS0"

*** sys_foo
- kernel
#+begin_src asm
; arch/x86/kernel/syscall_table_32.S
  ...
      .long sys_rt_tgsigqueueinfo	/* 335 */
      .long sys_perf_event_open
      .long sys_recvmmsg
      .long sys_foo               ;新增338
  ...
#+end_src
#+begin_src c
//kernel/sys.c
asmlinkage long sys_foo(void)
{
    return 0xabcd;
}
#+end_src
- app
#+begin_src c
  /* foo_app.c : gcc -static foo_app.c -o foo_app*/
  #include <stdio.h>
  #include <syscall.h>

  #define __NR_foo 338
  int main(int argc, char *argv[])
  {
      printf("new sys_call return 0x%x\n", syscall(__NR_foo));
      return 0;
  }
#+end_src
#+begin_src bash
#老的kernel
new sys_call return 0xffffffff

#修改过的kernel
new sys_call return 0xabcd
#+end_src

* 第六章 内核数据结构
** 链表
linux/list.h
#+begin_src c
  struct list_head {
      struct list_head *next, *prev;
  };

  #define LIST_HEAD_INIT(name) { &(name), &(name) } //静态声明
  #define LIST_HEAD(name) \
      struct list_head name = LIST_HEAD_INIT(name)

  static inline void INIT_LIST_HEAD(struct list_head *list) //动态
  {
      list->next = list;
      list->prev = list;
  }

  static inline void __list_add(struct list_head *new,
                    struct list_head *prev,
                    struct list_head *next)
  {
      next->prev = new;
      new->next = next;
      new->prev = prev;
      prev->next = new;
  }

  //加元素，在head后面
  static inline void list_add(struct list_head *new, struct list_head *head)
  {
      __list_add(new, head, head->next);
  }

  //加元素，在链表尾
  static inline void list_add_tail(struct list_head *new, struct list_head *head)
  {
      __list_add(new, head->prev, head);
  }

  static inline void __list_del(struct list_head * prev, struct list_head * next)
  {
      next->prev = prev;
      prev->next = next; //互相挂接
  }

  //删除元素
  static inline void list_del(struct list_head *entry)
  {
      __list_del(entry->prev, entry->next);
      entry->next = LIST_POISON1;
      entry->prev = LIST_POISON2;
  }


  static inline void list_move(struct list_head *list, struct list_head *head)
  {
      __list_del(list->prev, list->next); //list从当前链表退出
      list_add(list, head); //加到head后
  }

  static inline void list_move_tail(struct list_head *list,
                    struct list_head *head)
  {
      __list_del(list->prev, list->next);
      list_add_tail(list, head); //加到head->prev后
  }


  /* <= head <=> head1 <=> head2 <=> .... head_end => */
  /* <= list <=> list1 <=> list2 <=> .... list_end => */

  /* <= head <=> list1 <=> list2 <=> .... list_end <=> head1 <=> head2 ... head_end => */
  static inline void __list_splice(const struct list_head *list,
                   struct list_head *prev,
                   struct list_head *next)
  {
      struct list_head *first = list->next;
      struct list_head *last = list->prev;

      first->prev = prev;
      prev->next = first;         /* head <=> list->next */

      last->next = next;          /* head->next <=> list->prev*/
      next->prev = last;
  }

  static inline void list_splice(const struct list_head *list,
                  struct list_head *head)
  {
      if (!list_empty(list))
          __list_splice(list, head, head->next);
  }

/**
 * list_for_each	-	iterate over a list
 * @pos:	the &struct list_head to use as a loop cursor.
 * @head:	the head for your list.
 */
//遍历
 #define list_for_each(pos, head) \
	for (pos = (head)->next; prefetch(pos->next), pos != (head); \
        	pos = pos->next)

/**
 * list_entry - get the struct for this entry
 * @ptr:	the &struct list_head pointer.
 * @type:	the type of the struct this is embedded in.
 * @member:	the name of the list_struct within the struct.
 */
 #define list_entry(ptr, type, member) \
	container_of(ptr, type, member)

/**
 * list_for_each_entry	-	iterate over list of given type
 * @pos:	the type * to use as a loop cursor.
 * @head:	the head for your list.
 * @member:	the name of the list_struct within the struct.
 */
 #define list_for_each_entry(pos, head, member)				\
	for (pos = list_entry((head)->next, typeof(*pos), member);	\
	     prefetch(pos->member.next), &pos->member != (head); 	\
	     pos = list_entry(pos->member.next, typeof(*pos), member))

/**
 * list_for_each_safe - iterate over a list safe against removal of list entry
 * @pos:	the &struct list_head to use as a loop cursor.
 * @n:		another &struct list_head to use as temporary storage
 * @head:	the head for your list.
 */
//安全遍历，用于在foreach中删除元素
#define list_for_each_safe(pos, n, head) \
	for (pos = (head)->next, n = pos->next; pos != (head); \
		pos = n, n = pos->next)
#+end_src

** 数据队列
linux/kfifo.h
#+begin_src c
#define __kfifo_initializer(s, b) \
	(struct kfifo) { \
		.size	= s, \
		.in	= 0, \
		.out	= 0, \
		.buffer = b \
	}

//联合体，头为kfifo结构，后面为buffer size
#define DECLARE_KFIFO(name, size) \
union { \
	struct kfifo name; \
	unsigned char name##kfifo_buffer[size + sizeof(struct kfifo)]; \
}
/**
 * INIT_KFIFO - Initialize a kfifo declared by DECLARE_KFIFO
 * @name: name of the declared kfifo datatype
 */
#define INIT_KFIFO(name) \
	name = __kfifo_initializer(sizeof(name##kfifo_buffer) - \
				sizeof(struct kfifo), \
				name##kfifo_buffer + sizeof(struct kfifo))

//分离的结构，一个是kfifo，挂接buffer
#define DEFINE_KFIFO(name, size) \
	unsigned char name##kfifo_buffer[size]; \
	struct kfifo name = __kfifo_initializer(size, name##kfifo_buffer)

/**
 * kfifo_alloc - allocates a new FIFO internal buffer
 * @fifo: the fifo to assign then new buffer
 * @size: the size of the buffer to be allocated, this have to be a power of 2.
 * @gfp_mask: get_free_pages mask, passed to kmalloc()
 *
 * This function dynamically allocates a new fifo internal buffer
 *
 * The size will be rounded-up to a power of 2.
 * The buffer will be release with kfifo_free().
 * Return 0 if no error, otherwise the an error code
 */
//申请
int kfifo_alloc(struct kfifo *fifo, unsigned int size, gfp_t gfp_mask)

//推入
/**
 * kfifo_in - puts some data into the FIFO
 * @fifo: the fifo to be used.
 * @from: the data to be added.
 * @len: the length of the data to be added.
 *
 * This function copies at most @len bytes from the @from buffer into
 * the FIFO depending on the free space, and returns the number of
 * bytes copied.
 *
 * Note that with only one concurrent reader and one concurrent
 * writer, you don't need extra locking to use these functions.
 */
unsigned int kfifo_in(struct kfifo *fifo, const void *from,
				unsigned int len)


//取出
/**
 * kfifo_out - gets some data from the FIFO
 * @fifo: the fifo to be used.
 * @to: where the data must be copied.
 * @len: the size of the destination buffer.
 *
 * This function copies at most @len bytes from the FIFO into the
 * @to buffer and returns the number of copied bytes.
 *
 * Note that with only one concurrent reader and one concurrent
 * writer, you don't need extra locking to use these functions.
 */
unsigned int kfifo_out(struct kfifo *fifo, void *to, unsigned int len)
#+end_src

** 映射
linux/idr.h
不像python里的dict,key就是UID，是自动生成的
#+begin_src c
//初始化
/**
 * idr_init - initialize idr handle
 * @idp:	idr handle
 *
 * This function is use to set up the handle (@idp) that you will pass
 * to the rest of the functions.
 */
void idr_init(struct idr *idp)

//预分配UID
/**
 * idr_pre_get - reserver resources for idr allocation
 * @idp:	idr handle
 * @gfp_mask:	memory allocation flags
 *
 * This function should be called prior to locking and calling the
 * idr_get_new* functions. It preallocates enough memory to satisfy
 * the worst possible allocation.
 *
 * If the system is REALLY out of memory this function returns 0,
 * otherwise 1.
 */
int idr_pre_get(struct idr *idp, gfp_t gfp_mask)

//映射
/**
 * idr_get_new - allocate new idr entry
 * @idp: idr handle
 * @ptr: pointer you want associated with the id
 * @id: pointer to the allocated handle
 *
 * This is the allocate id function.  It should be called with any
 * required locks.
 *
 * If memory is required, it will return -EAGAIN, you should unlock
 * and go back to the idr_pre_get() call.  If the idr is full, it will
 * return -ENOSPC.
 *
 * @id returns a value in the range 0 ... 0x7fffffff
 */
int idr_get_new(struct idr *idp, void *ptr, int *id)

//根据UID取ptr
/**
 * idr_find - return pointer for given id
 * @idp: idr handle
 * @id: lookup key
 *
 * Return the pointer given the id it has been registered with.  A %NULL
 * return indicates that @id is not valid or you passed %NULL in
 * idr_get_new().
 *
 * This function can be called under rcu_read_lock(), given that the leaf
 * pointers lifetimes are correctly managed.
 */
void *idr_find(struct idr *idp, int id)

//删除UID
/**
 * idr_remove - remove the given id and free it's slot
 * @idp: idr handle
 * @id: unique key
 */
void idr_remove(struct idr *idp, int id)

//删除idr
/**
 * idr_destroy - release all cached layers within an idr tree
 * idp: idr handle
 */
void idr_destroy(struct idr *idp)
#+end_src

** 红黑树
linux/rbtree.h
#+begin_src c
//初始化
struct rb_root root = RB_ROOT;

//红黑树没有插入和查找接口，需自已实现
static inline struct page * rb_search_page_cache(struct inode * inode,
						 unsigned long offset)
{
	struct rb_node * n = inode->i_rb_page_cache.rb_node;
	struct page * page;

	while (n)
	{
		page = rb_entry(n, struct page, rb_page_cache);

		if (offset < page->offset)
			n = n->rb_left;
		else if (offset > page->offset)
			n = n->rb_right;
		else
			return page;
	}
	return NULL;
}

static inline struct page * rb_insert_page_cache(struct inode * inode,
						 unsigned long offset,
						 struct rb_node * node)
{
	struct page * ret;
	if ((ret = __rb_insert_page_cache(inode, offset, node)))
		goto out;
	rb_insert_color(node, &inode->i_rb_page_cache);
 out:
	return ret;
}
#+end_src

* 第七章 中断和中断处理

中断可能随时发生，中断上下文不可阻塞

上半部 - 处理有严格时限的工作
下半部 - 处理大量逻辑的工作

request_irq里会调用kmalloc，有时会导致睡眠
#+begin_src c
/* irq     中断号 */
/* handler 中断处理程序 */
/* flags   中断处理标志 */
/* - IRQF_DISABLE       中断处理程序时禁止所有中断 */
/* - IRQF_SAMPLE_RANDOM 随机熵源 */
/* - IRQF_TIMER         专为系统定时器的中断处理 */
/* - IRQF_SHARED        共享中断线 */
/* name    ASCII文本 */
/* dev     共享中断时的priv指针 */
typedef irqreturn_t (*irq_handler_t)(int, void *);
static inline int __must_check
request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags,
	    const char *name, void *dev)
{
	return request_threaded_irq(irq, handler, NULL, flags, name, dev);
}

extern void free_irq(unsigned int, void *);
#+end_src

*linux的中断处理程序无须重入，当一个中断执行时，相应的中断号会在所有处理器上被屏蔽，同一个中断处理程充绝不会同时被调用以处理嵌套中断*

共享中断要求
1. IRQF_SHARED
2. dev参数唯一
3. 必须区分是自已的设备产生了中断，而不是共享了这个中断号的其他设备

中断上下文和进程无关，所以不可以睡眠，同时有严格的时间限制

中断流程
硬件产生一个中断 -> 中断控制器 -> 处理器 -> 处理器中断内核 -> do_IRQ() -> handle_IRQ_event() 可能在此开启其他中断 -> 运行挂接的所有中断处理程序 -> 关中断 -> ret_from_intr()

#+begin_src c
/*
 * do_IRQ handles all normal device IRQ's (the special
 * SMP cross-CPU interrupts have their own specific
 * handlers).
 */
unsigned int __irq_entry do_IRQ(struct pt_regs *regs)
{
	struct pt_regs *old_regs = set_irq_regs(regs);

	/* high bit used in ret_from_ code  */
	unsigned vector = ~regs->orig_ax;
	unsigned irq;

	exit_idle();
	irq_enter();

	irq = __get_cpu_var(vector_irq)[vector];

	if (!handle_irq(irq, regs)) {
		ack_APIC_irq();

		if (printk_ratelimit())
			pr_emerg("%s: %d.%d No irq handler for vector (irq %d)\n",
				__func__, smp_processor_id(), vector, irq);
	}

	irq_exit();

	set_irq_regs(old_regs);
	return 1;
}
#+end_src

#+begin_src asm
ret_from_intr:
	GET_THREAD_INFO(%ebp)
check_userspace:
	movl PT_EFLAGS(%esp), %eax	# mix EFLAGS and CS
	movb PT_CS(%esp), %al //检查栈中的cs，是否是用户权限来判断是否从用户态中断
	andl $(X86_EFLAGS_VM | SEGMENT_RPL_MASK), %eax
	cmpl $USER_RPL, %eax
	jb resume_kernel		# not returning to v8086 or userspace

ENTRY(resume_userspace)
	LOCKDEP_SYS_EXIT
 	DISABLE_INTERRUPTS(CLBR_ANY)	# make sure we don't miss an interrupt
					# setting need_resched or sigpending
					# between sampling and the iret
	TRACE_IRQS_OFF
	movl TI_flags(%ebp), %ecx
	andl $_TIF_WORK_MASK, %ecx	# is there any work to be done on
					# int/exception return?
	jne work_pending
	jmp restore_all
#+end_src

如下，第一列中断号，第二列是中断计数，第三列是中断控制器，第四列是中断名
#+begin_src bash
         CPU0       
  0:        268   IO-APIC-edge      timer
  1:       3261   IO-APIC-edge      i8042
  4:      31532   IO-APIC-edge    
  8:          1   IO-APIC-edge      rtc0
  9:          0   IO-APIC-fasteoi   acpi
 12:       6289   IO-APIC-edge      i8042
 14:          0   IO-APIC-edge      ata_piix
 15:          0   IO-APIC-edge      ata_piix
 16:     229317   IO-APIC-fasteoi   eth1
 17:      52749   IO-APIC-fasteoi   ioc0, Ensoniq AudioPCI
 18:        228   IO-APIC-fasteoi   ehci_hcd:usb1, uhci_hcd:usb2
#+end_src

中断控制
| Name               | 说明                                                     | 可否嵌套 |
|--------------------+----------------------------------------------------------+----------|
| local_irq_disable  | 禁止本地中断                                             | 否       |
| local_irq_enable   | 使能本地中断                                             | 否       |
| local_irq_save     | 保存本地中断状态，禁止本地中断                           | 是       |
| local_irq_restore  | 恢复之前的中断状态                                       | 是       |
| disable_irq        | 等待所有处理程序完毕，才关指点定中断线                   | 是       |
| disable_irq_nosync | 不等，直接关                                             | 是       |
| enable_irq         | 使能指定中断线                                           | N/A      |
| synchronize_irq    | 等待直到中断处理程序退出                                 | N/A      |
| irqs_disabled      | 本地中断是否关闭                                         | N/A      |
| in_interrupt       | 中断上下文为0(包括下半部，判断软件标记位)，进程上下文为1 | N/A      |
| in_irq             | 正在执行中断处理程为1                                    | N/A      |
